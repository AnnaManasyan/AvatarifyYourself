{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJT1kjF67YSq",
        "outputId": "68830a09-8c97-4960-838d-5f4e89ae0792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m986.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.13 requires torch<2.2,>=1.10, but you have torch 2.2.0 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade \\\n",
        "  diffusers~=0.16 \\\n",
        "  transformers~=4.28 \\\n",
        "  safetensors~=0.3 \\\n",
        "  sentencepiece~=0.1 \\\n",
        "  accelerate~=0.18 \\\n",
        "  bitsandbytes~=0.38 \\\n",
        "  torch~=2.0 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121 -q\n",
        "!pip install kaolin==0.15.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.1.0_cu121.html -q\n",
        "!git clone https://github.com/YuliangXiu/TEXTure.git -q\n",
        "!pip install huggingface_hub --upgrade -q\n",
        "!pip install loguru einops -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8HUm91F7ddr",
        "outputId": "17baa6cd-f708-4765-e236-4a0757cab8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m469.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.7/255.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pygltflib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('TEXTure')\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPgqdm-c-uHx",
        "outputId": "36804468-97a7-4543-eb3e-a4b62b77f394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja (from -r requirements.txt (line 7))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xatlas (from -r requirements.txt (line 8))\n",
            "  Downloading xatlas-0.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.4/229.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrallis (from -r requirements.txt (line 11))\n",
            "  Downloading pyrallis-0.3.1-py3-none-any.whl (33 kB)\n",
            "Collecting av (from -r requirements.txt (line 12))\n",
            "  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.4.9)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.10/dist-packages (from pyrallis->-r requirements.txt (line 11)) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from pyrallis->-r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg->-r requirements.txt (line 13)) (67.7.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect->pyrallis->-r requirements.txt (line 11)) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect->pyrallis->-r requirements.txt (line 11)) (4.9.0)\n",
            "Installing collected packages: xatlas, ninja, av, pyrallis\n",
            "Successfully installed av-11.0.0 ninja-1.11.1.1 pyrallis-0.3.1 xatlas-0.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.run_texture --config_path=configs/text_guided/avatar.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_pOYIAf_5NN",
        "outputId": "97997157-c7a2-48a2-c0ac-dd43382127e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2024-01-31 21:55:54\u001b[0m \u001b[1mLoaded Mesh, #parameters: 6337536\u001b[0m\n",
            "\u001b[32m2024-01-31 21:55:54\u001b[0m \u001b[1mloaded hugging face access token from ./TOKEN!\u001b[0m\n",
            "\u001b[32m2024-01-31 21:55:54\u001b[0m \u001b[1mloading stable diffusion with stabilityai/stable-diffusion-2-depth...\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1900: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2894: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "\u001b[32m2024-01-31 21:56:41\u001b[0m \u001b[1m\t successfully loaded stable diffusion!\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:41\u001b[0m \u001b[1mbad anatomy, bad proportions, blurry, cropped, deformed, disfigured, duplicate, extra fingers, extra limbs, fused fingers, long neck, low quality, lowres, malformed limbs, missing arms, mutated hands, mutilated, out of frame, poorly drawn face, poorly drawn hands, too many fingers, ugly, worst quality\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:41\u001b[0m \u001b[1mbad anatomy, bad proportions, blurry, cropped, deformed, disfigured, duplicate, extra fingers, extra limbs, fused fingers, long neck, low quality, lowres, malformed limbs, missing arms, mutated hands, mutilated, out of frame, poorly drawn face, poorly drawn hands, too many fingers, ugly, worst quality\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:41\u001b[0m \u001b[1mbad anatomy, bad proportions, blurry, cropped, deformed, disfigured, duplicate, extra fingers, extra limbs, fused fingers, long neck, low quality, lowres, malformed limbs, missing arms, mutated hands, mutilated, out of frame, poorly drawn face, poorly drawn hands, too many fingers, ugly, worst quality\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:42\u001b[0m \u001b[1mbad anatomy, bad proportions, blurry, cropped, deformed, disfigured, duplicate, extra fingers, extra limbs, fused fingers, long neck, low quality, lowres, malformed limbs, missing arms, mutated hands, mutilated, out of frame, poorly drawn face, poorly drawn hands, too many fingers, ugly, worst quality\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:42\u001b[0m \u001b[1mbad anatomy, bad proportions, blurry, cropped, deformed, disfigured, duplicate, extra fingers, extra limbs, fused fingers, long neck, low quality, lowres, malformed limbs, missing arms, mutated hands, mutilated, out of frame, poorly drawn face, poorly drawn hands, too many fingers, ugly, worst quality\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:42\u001b[0m \u001b[1mbad anatomy, bad proportions, blurry, cropped, deformed, disfigured, duplicate, extra fingers, extra limbs, fused fingers, long neck, low quality, lowres, malformed limbs, missing arms, mutated hands, mutilated, out of frame, poorly drawn face, poorly drawn hands, too many fingers, ugly, worst quality\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:42\u001b[0m \u001b[1mSuccessfully initialized vera_1\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:42\u001b[0m \u001b[1mStarting training ^_^\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:42\u001b[0m \u001b[1mEvaluating and saving model, painting iteration #0...\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:51\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:51\u001b[0m \u001b[1m--- Painting step #1 ---\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:51\u001b[0m \u001b[1mPainting from theta: 1.0471975803375244, phi: 0.0, radius: 1.5\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:53\u001b[0m \u001b[1mtext: High res image of women wearing orange sweater, white pants, brown hair, looking at the camera.\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:54\u001b[0m \u001b[1mUpdate ratio 0.00103 is small for an editing step, skipping\u001b[0m\n",
            "\u001b[32m2024-01-31 21:56:54\u001b[0m \u001b[1mEvaluating and saving model, painting iteration #1...\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:03\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:03\u001b[0m \u001b[1m--- Painting step #2 ---\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:03\u001b[0m \u001b[1mPainting from theta: 1.0471975803375244, phi: 1.5707963705062866, radius: 1.5\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:05\u001b[0m \u001b[1mtext: High res image of women wearing orange sweater, white pants, brown hair, looking at the camera.\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:05\u001b[0m \u001b[1mUpdate ratio 0.00048 is small for an editing step, skipping\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:05\u001b[0m \u001b[1mEvaluating and saving model, painting iteration #2...\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:14\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:14\u001b[0m \u001b[1m--- Painting step #3 ---\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:14\u001b[0m \u001b[1mPainting from theta: 1.0471975803375244, phi: 4.71238899230957, radius: 1.5\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:16\u001b[0m \u001b[1mtext: High res image of women wearing orange sweater, white pants, brown hair, looking at the camera.\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:17\u001b[0m \u001b[1mUpdate ratio 0.00108 is small for an editing step, skipping\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:17\u001b[0m \u001b[1mEvaluating and saving model, painting iteration #3...\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:26\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:26\u001b[0m \u001b[1m--- Painting step #4 ---\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:26\u001b[0m \u001b[1mPainting from theta: 1.0471975803375244, phi: 3.1415927410125732, radius: 1.5\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:28\u001b[0m \u001b[1mtext: High res image of women wearing orange sweater, white pants, brown hair, looking at the camera.\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:28\u001b[0m \u001b[1mUpdate ratio 0.00157 is small for an editing step, skipping\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:28\u001b[0m \u001b[1mEvaluating and saving model, painting iteration #4...\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:37\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:37\u001b[0m \u001b[1m--- Painting step #5 ---\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:37\u001b[0m \u001b[1mPainting from theta: 0.5235987901687622, phi: 3.1415927410125732, radius: 1.5\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:39\u001b[0m \u001b[1mtext: High res image of women wearing orange sweater, white pants, brown hair, looking at the camera.\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:40\u001b[0m \u001b[1mUpdate ratio 0.00109 is small for an editing step, skipping\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:40\u001b[0m \u001b[1mEvaluating and saving model, painting iteration #5...\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:49\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:49\u001b[0m \u001b[1m--- Painting step #6 ---\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:49\u001b[0m \u001b[1mPainting from theta: 2.6179938316345215, phi: 3.1415927410125732, radius: 1.5\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:51\u001b[0m \u001b[1mtext: High res image of women wearing orange sweater, white pants, brown hair, looking at the camera.\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:51\u001b[0m \u001b[1mUpdate ratio 0.00008 is small for an editing step, skipping\u001b[0m\n",
            "\u001b[32m2024-01-31 21:57:51\u001b[0m \u001b[1mEvaluating and saving model, painting iteration #6...\u001b[0m\n",
            "\u001b[32m2024-01-31 21:58:00\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2024-01-31 21:58:00\u001b[0m \u001b[1mFinished Painting ^_^\u001b[0m\n",
            "\u001b[32m2024-01-31 21:58:00\u001b[0m \u001b[1mSaving the last result...\u001b[0m\n",
            "\u001b[32m2024-01-31 21:58:00\u001b[0m \u001b[1mEvaluating and saving model, painting iteration #6...\u001b[0m\n",
            "\u001b[32m2024-01-31 21:59:23\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2024-01-31 21:59:23\u001b[0m \u001b[1mSaving mesh to experiments/vera_1/mesh\u001b[0m\n",
            "\u001b[32m2024-01-31 21:59:23\u001b[0m \u001b[1mwriting obj mesh to {obj_file}\u001b[0m\n",
            "\u001b[32m2024-01-31 21:59:23\u001b[0m \u001b[1mwriting vertices {v_np.shape}\u001b[0m\n",
            "\u001b[32m2024-01-31 21:59:23\u001b[0m \u001b[1mwriting vertices texture coords {vt_np.shape}\u001b[0m\n",
            "\u001b[32m2024-01-31 21:59:23\u001b[0m \u001b[1mwriting faces {f_np.shape}\u001b[0m\n",
            "\u001b[32m2024-01-31 21:59:25\u001b[0m \u001b[1m\tDone!\u001b[0m\n",
            "\u001b[32m2024-01-31 21:59:25\u001b[0m \u001b[1m\tDone!\u001b[0m\n",
            "100% 6/6 [02:33<00:00, 25.64s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nYwkPltWFcaz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}